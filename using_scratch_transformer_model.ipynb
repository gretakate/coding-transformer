{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export PYTHONPATH=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kintzgk2/Documents/Personal/PersonalProject/coding-transformer/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_upload.scratch_transformer_model.configuration_scratch_transformer import ScratchTransformerConfig\n",
    "from huggingface_upload.scratch_transformer_model.model_scratch_transformer import ScratchTransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_ds, get_config\n",
    "from config import get_weights_file_path\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "cfg = get_config()\n",
    "cfg['model_folder'] = 'weights'\n",
    "cfg['tokenizer_file'] = 'vocab/tokenizer{0}.json'\n",
    "cfg['preload'] = '29'\n",
    "\n",
    "# train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(cfg)\n",
    "tokenizer_src = Tokenizer.from_file(str('vocab/tokenizeren.json'))\n",
    "tokenizer_tgt = Tokenizer.from_file(str('vocab/tokenizerit.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_tgt.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_transformer_config = ScratchTransformerConfig(\n",
    "                                                    src_vocab_size=tokenizer_src.get_vocab_size(), \n",
    "                                                    tgt_vocab_size=tokenizer_tgt.get_vocab_size(), \n",
    "                                                    )\n",
    "scratch_transformer = ScratchTransformerModel(scratch_transformer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_transformer.config.decoder_start_token_id = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
    "scratch_transformer.config.pad_token_id = tokenizer_tgt.token_to_id(\"[PAD]\")\n",
    "scratch_transformer.config.eos_token_id = tokenizer_tgt.token_to_id(\"[EOS]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sentence = \"Translate this sentence to italian for me.\"\n",
    "\n",
    "source = tokenizer_src.encode(sentence)\n",
    "source = torch.cat([\n",
    "    torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64), \n",
    "    torch.tensor(source.ids, dtype=torch.int64),\n",
    "    torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64),\n",
    "    torch.tensor([tokenizer_src.token_to_id('[PAD]')] * (scratch_transformer.config.seq_len - len(source.ids) - 2), dtype=torch.int64)\n",
    "], dim=0)\n",
    "\n",
    "# Mask out all of the padding tokens\n",
    "source_mask = (source != tokenizer_src.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=None, logits=tensor([[    2, 16616, 18779, 16119, 18675,  7345, 12435, 14926,  4444, 15145,\n",
       "         19756, 20220,  2067,  2067, 20220,  4444,  9227, 21822, 18675, 21822,\n",
       "          9227,  2067,  2067,  2067, 20220,  2067,  2067, 20220,  2067, 21112,\n",
       "          8727, 20220,  8727, 16616, 19562,  1171,  2067, 21112, 21112, 21112,\n",
       "         21112, 21112, 21112, 21112, 21112, 20220, 12908, 19158, 21112, 20220,\n",
       "          5186, 20237, 20220, 18779, 12435, 21112,  2338,  9227,  2067, 12435,\n",
       "         18779,  2338, 20220, 11664,  2338, 20220, 20220, 16119, 16119,  2338,\n",
       "          9227,  9227,  2067, 13641,  2338,  9227,  9227, 17586,  2338,  1171,\n",
       "          7831,  9227,  1171,  2338,  9227,  9227,  9227,  2067, 21112,  2338,\n",
       "          9227, 20237, 19756,  9227,  4726,  1095,  2338,  9227,  2067,  4029,\n",
       "         20220,  9227, 20220,  2338,  2338, 10991, 19562,  2338,  9227, 20220,\n",
       "         16616, 18779,  4029, 19562,  5186,  9227, 19562, 21112,   577, 18779,\n",
       "         15145,   577, 18779, 17586,  9227,  2694,  2694, 20220,  2694, 19562,\n",
       "          2338, 12435,  9227,  9227,  2067, 21112, 20220, 21112,  2694, 12435,\n",
       "         20220,  2067, 21112, 19562, 20220,  2067,  4029, 19562, 18779, 12435,\n",
       "         19562, 21112,  2694,  9227, 21822,  5146,  2067, 20220,  7345, 21112,\n",
       "         21112, 18779, 18779, 20220, 18779, 21112,  7345,  5403, 21112, 20220,\n",
       "         21112, 21112, 21112, 21112, 20220,  7345, 21112, 20237, 19562,  7345,\n",
       "         21112, 21112, 10627,  4029,  2338,  2067,  2067,  2067, 20220, 21686,\n",
       "         21112, 20220, 21112, 20220, 21112,  7345, 20805,  5306, 15145, 21822,\n",
       "         21112, 17586, 21112, 21112,  5146,  7831, 18779,  4029, 21112, 21112,\n",
       "         17586, 19562,  2338,  9247, 21112,  2338, 18302,  7345,  4029,  4029,\n",
       "          7345, 19562,  7345, 19562, 18779, 20805, 12425,  4444, 15786,  4029,\n",
       "          2694, 21112,  7345, 21112,  2694,  5146,  2338,  7345,  2067,  7345,\n",
       "          7345,  7345,  9947,  7345,  7345,  4161,  7345,  2067,  7345,  7345,\n",
       "          7345,  7345, 20805, 21112,  7345,  7345, 20805,  7345,  7345,  4444,\n",
       "         19562,  4444,  9947, 21112, 21112,  7345,  7345, 18779, 21112, 16616,\n",
       "          7345,  7345,  9947, 19562,  7345,  7345,  2694, 15145, 10991, 19562,\n",
       "         10991, 18779,  4444,  7345,  7345,  7345,  2694, 20220,  7345, 13727,\n",
       "         21112, 21112, 21112,  7345,  7345, 19562,  7345,  7345, 19562,  7345,\n",
       "         21112,  2247,  7345,  4161, 10087,  4161, 18779,  4726,  7345, 13630,\n",
       "         19562,  7345,  7345,  7345,  7345,  7345,  7345, 15145,  9947,  7345,\n",
       "          7345,  2694,  7345, 16687,  7345,  7345,  7345,  7345,  7345, 18779,\n",
       "         19562,  2338, 19562,  7345,  7345, 19562,  4029, 19562,  7345,  4029,\n",
       "          4444,  4161,  9227,  7345,  4444,  7345,  7345, 19562,  9227,  4029]]), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=None, encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scratch_transformer(input_ids=source, attention_mask=source_mask)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spirito finanziario Bisognerà fabbriferrai accordato scherzava permisero focolare rammentarsi meraviglierei pegno governo governo pegno focolare Michajla staffa fabbriferrai staffa Michajla governo governo governo pegno governo governo pegno governo rivoluzionaria occorsero pegno occorsero Spirito lascierò sedia governo rivoluzionaria rivoluzionaria rivoluzionaria rivoluzionaria rivoluzionaria rivoluzionaria rivoluzionaria rivoluzionaria pegno Eccellenza imperator rivoluzionaria pegno tuttora percepiva pegno finanziario scherzava rivoluzionaria trovar Michajla governo scherzava finanziario trovar pegno golfo trovar pegno pegno Bisognerà Bisognerà trovar Michajla Michajla governo celebrare trovar Michajla Michajla calare trovar sedia predicare Michajla sedia trovar Michajla Michajla Michajla governo rivoluzionaria trovar Michajla percepiva meraviglierei Michajla italiana appunto trovar Michajla governo nascondeva pegno Michajla pegno trovar trovar apprendere lascierò trovar Michajla pegno Spirito finanziario nascondeva lascierò tuttora Michajla lascierò rivoluzionaria carrozza finanziario rammentarsi carrozza finanziario calare Michajla corda corda pegno corda lascierò trovar scherzava Michajla Michajla governo rivoluzionaria pegno rivoluzionaria corda scherzava pegno governo rivoluzionaria lascierò pegno governo nascondeva lascierò finanziario scherzava lascierò rivoluzionaria corda Michajla staffa seguitò governo pegno accordato rivoluzionaria rivoluzionaria finanziario finanziario pegno finanziario rivoluzionaria accordato immaginato rivoluzionaria pegno rivoluzionaria rivoluzionaria rivoluzionaria rivoluzionaria pegno accordato rivoluzionaria percepiva lascierò accordato rivoluzionaria rivoluzionaria vibrare nascondeva trovar governo governo governo pegno sovrano rivoluzionaria pegno rivoluzionaria pegno rivoluzionaria accordato respingendo colpita rammentarsi staffa rivoluzionaria calare rivoluzionaria rivoluzionaria seguitò predicare finanziario nascondeva rivoluzionaria rivoluzionaria calare lascierò trovar Qualcuno rivoluzionaria trovar diavolacci accordato nascondeva nascondeva accordato lascierò accordato lascierò finanziario respingendo scarsezza focolare tartari nascondeva corda rivoluzionaria accordato rivoluzionaria corda seguitò trovar accordato governo accordato accordato accordato istrumento accordato accordato camino accordato governo accordato accordato accordato accordato respingendo rivoluzionaria accordato accordato respingendo accordato accordato focolare lascierò focolare istrumento rivoluzionaria rivoluzionaria accordato accordato finanziario rivoluzionaria Spirito accordato accordato istrumento lascierò accordato accordato corda rammentarsi apprendere lascierò apprendere finanziario focolare accordato accordato accordato corda pegno accordato comparso rivoluzionaria rivoluzionaria rivoluzionaria accordato accordato lascierò accordato accordato lascierò accordato rivoluzionaria impeto accordato camino ordinava camino finanziario italiana accordato cavallerizzo lascierò accordato accordato accordato accordato accordato accordato rammentarsi istrumento accordato accordato corda accordato Vede accordato accordato accordato accordato accordato finanziario lascierò trovar lascierò accordato accordato lascierò nascondeva lascierò accordato nascondeva focolare camino Michajla accordato focolare accordato accordato lascierò Michajla nascondeva'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_tgt.decode(results.logits[0].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try preloading the model from a weights file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filename = get_weights_file_path(cfg, cfg['preload'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state = torch.load(model_filename, map_location=torch.device(device))\n",
    "\n",
    "scratch_transformer.model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La terminò questa frase le vostre di me .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_logits = scratch_transformer(input_ids=source, attention_mask=source_mask)\n",
    "tokenizer_tgt.decode(pretrained_logits.logits[0].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try with generating loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kintzgk2/Documents/Personal/PersonalProject/coding-transformer/huggingface/scratch_transformer_model/model_scratch_transformer.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n"
     ]
    }
   ],
   "source": [
    "tgt_sentence = \"Traducimi questa frase in italiano.\"\n",
    "\n",
    "tgt_tokens = tokenizer_tgt.encode(tgt_sentence)\n",
    "dec_num_padding_tokens = scratch_transformer.config.seq_len - len(tgt_tokens) - 1\n",
    "\n",
    "decoder_input = torch.cat(\n",
    "            [\n",
    "                torch.tensor(tgt_tokens.ids, dtype=torch.int64),\n",
    "                torch.tensor([tokenizer_tgt.token_to_id('[EOS]')], dtype=torch.int64),\n",
    "                torch.tensor([tokenizer_tgt.token_to_id('[PAD]')] * dec_num_padding_tokens, dtype=torch.int64)\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "pretrained_results = scratch_transformer(input_ids=source, attention_mask=source_mask, decoder_input_ids=decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: Traducimi questa frase in italiano.\n",
      "PREDICTED: La terminò questa frase le vostre di me .\n",
      "Loss: 11.37087631225586\n"
     ]
    }
   ],
   "source": [
    "print(f\"TARGET: {tgt_sentence}\")\n",
    "print(f\"PREDICTED: {tokenizer_tgt.decode(pretrained_logits.logits[0].tolist())}\")\n",
    "print(f\"Loss: {pretrained_results.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e9690d57cb1a2679a5efa60e153215b1ab6c2c076dfbf33af3186832e554dc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
