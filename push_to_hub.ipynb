{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing the custom model to huggingface hub\n",
    "\n",
    "The following notebook is provided as a reference for how I pushed the custom model code to huggingface. Note that it should not be run, as the model and config has already been registered.\n",
    "\n",
    "Reference: https://huggingface.co/docs/transformers/v4.39.1/custom_models#sending-the-code-to-the-hub\n",
    "\n",
    "```\n",
    ".\n",
    "└── scratch_transformer_model\n",
    "    ├── __init__.py\n",
    "    ├── configuration_scratch_transformer.py\n",
    "    ├── modeling_scratch_transformer.py\n",
    "    └── model.py\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To share your model with the community, follow those steps: first import the ScratchTransformer model and config from the newly created files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export PYTHONPATH=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_upload.scratch_transformer_model.configuration_scratch_transformer import ScratchTransformerConfig\n",
    "from huggingface_upload.scratch_transformer_model.model_scratch_transformer import ScratchTransformerModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you have to tell the library you want to copy the code files of those objects when using the save_pretrained method and properly register them with a given Auto class (especially for models) by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScratchTransformerConfig.register_for_auto_class()\n",
    "ScratchTransformerModel.register_for_auto_class(\"AutoModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s create the config and models, and load the model with the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from train import get_config\n",
    "from config import get_weights_file_path\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "cfg = get_config()\n",
    "cfg['model_folder'] = 'weights'\n",
    "cfg['tokenizer_file'] = 'vocab/tokenizer{0}.json'\n",
    "cfg['preload'] = '29'\n",
    "\n",
    "tokenizer_src = Tokenizer.from_file(str('vocab/tokenizeren.json'))\n",
    "tokenizer_tgt = Tokenizer.from_file(str('vocab/tokenizerit.json'))\n",
    "\n",
    "scratch_transformer_config = ScratchTransformerConfig(\n",
    "                                                    src_vocab_size=tokenizer_src.get_vocab_size(), \n",
    "                                                    tgt_vocab_size=tokenizer_tgt.get_vocab_size(), \n",
    "                                                    )\n",
    "scratch_transformer = ScratchTransformerModel(scratch_transformer_config)\n",
    "\n",
    "scratch_transformer.config.decoder_start_token_id = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
    "scratch_transformer.config.pad_token_id = tokenizer_tgt.token_to_id(\"[PAD]\")\n",
    "scratch_transformer.config.eos_token_id = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
    "\n",
    "# This is where I load the model from my checkpoint weights file!!\n",
    "model_filename = get_weights_file_path(cfg, cfg['preload'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state = torch.load(model_filename, map_location=torch.device(device))\n",
    "scratch_transformer.model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to send the model to the Hub, make sure you are logged in. Either run in a terminal:\n",
    "\n",
    "```\n",
    "huggingface-cli login\n",
    "```\n",
    "\n",
    "Or in the notebook (** note that there are sometimes issues with vscode with this, here's a [workaround](https://github.com/huggingface/huggingface_hub/issues/752#issuecomment-1063793855)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06bd01b573349e09bf00f0fb9099d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then push to your own namespace (or an organization you are a member of) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1a04b498ce459984362148ac09bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/gretakate/english-to-italian-transformer-from-scratch/commit/e857b0518ae6d8dd6d52f7f8575d85a39ee7f81f', commit_message='Upload model', commit_description='', oid='e857b0518ae6d8dd6d52f7f8575d85a39ee7f81f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scratch_transformer.push_to_hub(\"gretakate/english-to-italian-transformer-from-scratch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of the modeling weights and the configuration in json format, this also copied the modeling and configuration .py files in the folder scratch_transformer_model and uploaded the result to the Hub. You can check the result in this model repo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the transformer model\n",
    "\n",
    "\n",
    "References:\n",
    "- https://huggingface.co/docs/transformers/v4.39.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel\n",
    "- https://colab.research.google.com/drive/1WIk2bxglElfZewOHboPFNj8H44_VAyKE?usp=sharing#scrollTo=ZwQIEhKOrJpl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e9690d57cb1a2679a5efa60e153215b1ab6c2c076dfbf33af3186832e554dc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
